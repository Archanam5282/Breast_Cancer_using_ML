###################################### Decision Tree Model #######################################
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=5)
DT = DecisionTreeClassifier()
DT.fit(X_train, y_train)
#predicting
y_pred_DT=DT.predict(X_test)
#confusion matrix for both data
cnf_DT= metrics.confusion_matrix(y_test, y_pred_DT)
cnf_DT

#Accurary , pre and recall for DT
print("Accuracy:",metrics.accuracy_score(y_test, y_pred_DT))
print("Precision:",metrics.precision_score(y_test, y_pred_DT))
print("Recall:",metrics.recall_score(y_test, y_pred_DT))

# importing data
Dataset = pd.read_csv("C:\\Users\\12035_\\OneDrive\\Desktop\\UNH Studies\\02_AI\\Final project (BC)\\Data.csv")
#cleaning steps
Dataset.loc[Dataset['diagnosis'] == "M", 'target'] = 0 
Dataset.loc[Dataset['diagnosis'] =="B", 'target'] = 1
del Dataset['diagnosis']
X=Dataset.drop(['target'], axis=1)
y=Dataset['target']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=5)

#print(y)

## Optimising hyperparameter of a decision tree model using Grid search
def Snippet_146():
    print()
    
    import warnings
    warnings.filterwarnings("ignore")

    # load libraries
    from sklearn import decomposition, datasets
    from sklearn import tree
    from sklearn.model_selection import GridSearchCV, cross_val_score
    from sklearn.preprocessing import StandardScaler
    from sklearn.pipeline import Pipeline


    # importing data
    Dataset = pd.read_csv("C:\\Users\\12035_\\OneDrive\\Desktop\\UNH Studies\\02_AI\\Final project (BC)\\Data.csv")
    #cleaning steps
    Dataset.loc[Dataset['diagnosis'] == "M", 'target'] = 0 
    Dataset.loc[Dataset['diagnosis'] =="B", 'target'] = 1
    del Dataset['diagnosis']
    X=Dataset.drop(['target'], axis=1)
    y=Dataset['target']
    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=5)

    #print(y)

    # scaler object creation
    sc = StandardScaler()

    #pca object creation
    pca = decomposition.PCA()

    # Create a decision tree object
    decisiontree = tree.DecisionTreeClassifier()

    # Create a dictionary 
    #First element with standardising data
    # Second, tranforming the data with PCA method
    # last decision tree training
    pipe = Pipeline(steps=[('sc', sc),
                           ('pca', pca),
                           ('decisiontree', decisiontree)])

    # Create n components 
    n_components = list(range(1,X_train.shape[1]+1,1))


    # Create a dictionary of all the parameter options 
    parameters = dict(pca__n_components=n_components,
                      decisiontree__criterion=['gini', 'entropy'],
                      decisiontree__max_depth= [4,6,8,12])

    # Creating a grid search object
    clf = GridSearchCV(pipe, parameters)

    # Fitting the grid
    clf.fit(X_train, y_train)

    # View The optimised Parameters
    print('Optimised Criterion:', clf.best_estimator_.get_params()['decisiontree__criterion'])
    print('Optimised max_depth:', clf.best_estimator_.get_params()['decisiontree__max_depth'])
    print('Optimised Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])
    print(); print(clf.best_estimator_.get_params()['decisiontree'])

    # Use Cross Validation To Evaluate Model
    Result = cross_val_score(clf, X_train, y_train, cv=4, n_jobs=-1)
    print(); print(Result)
    #mean
    print(); print(Result.mean())
    #std
    print(); print(Result.std())

Snippet_146()
